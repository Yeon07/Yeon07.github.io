<!DOCTYPE html> 
<html lang="en">
   <head>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
      <meta http-equiv="X-UA-Compatible" content="IE=edge">
      <title>Publications | Seoyeon Kim</title>
      <meta name="author" content="Seoyeon Kim"/>
      <meta name="description" content="Seoyeon's personal webpage. Based on [*folio](https://github.com/bogoli/-folio) design. "/>
      <meta name="keywords" content="seoyeon"/>
      <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/>
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
      <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/vs.css" media="none" id="highlight_theme_light"/>
      <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üî•</text></svg>">
      <link rel="stylesheet" href="/assets/css/main.css">
      <link rel="canonical" href="https://yeon07.github.io/publications/">
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/zenburn.css" media="none" id="highlight_theme_dark"/>
      <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> 
   </head>
   <body class="fixed-top-nav ">
      <header>
         <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
            <div class="container">
               <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Seoyeon </span>Kim</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> 
               <div class="collapse navbar-collapse text-right" id="navbarNav">
                  <ul class="navbar-nav ml-auto flex-nowrap">
                     <li class="nav-item "> <a class="nav-link" href="/">About</a> </li>
                     <!--<li class="nav-item "> <a class="nav-link" href="/blog/">Blog</a> </li>-->
                     <li class="nav-item"> <a class="nav-link" href="/assets/pdf/cv_seoyeon.pdf" target="_blank" rel="noopener noreferrer">Curriculum Vitae</a> </li>
                     <li class="nav-item active"> <a class="nav-link" href="/publications/">Publications<span class="sr-only">(current)</span></a> </li>
                     <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li>
                  </ul>
               </div>
            </div>
         </nav>
      </header>
      <div class="container mt-5">
         <div class="post">
            <header class="post-header">
               <h1 class="post-title">Publications</h1>
               <p class="post-description"></p>
            </header>
            <article>
               <div class="publications">
                  <h2 class="year">2023</h2>
                  <ol class="bibliography">
                     <li>
                        <div class="row">
                           <div class="col-sm-4">
                              <figure>
                                 <picture>
                                    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/kim2023risclipv2-480.webp">
                                    </source> 
                                    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/kim2023risclipv2-800.webp">
                                    </source> 
                                    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/kim2023risclipv2-1400.webp">
                                    </source> <img src="/assets/img/publication_preview/kim2023risclipv2.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> 
                                 </picture>
                              </figure>
                           </div>
                           <div id="kim2023risclip" class="col-sm-8">
                            <div class="title">RISCLIP: Referring Image Segmentation Framework using CLIP</div>
                            <div class="author"> <b>Seoyeon Kim</b>,  Minguk Kang,  and Jaesik Park </div>
                            <div class="periodical"> <em>Under Submission,</em> 2023 </div>
                            <!-- <div class="periodical"> <em>International Conference on Neural Information Processing Systems (<b>NeurlPS</b>),</em> 2023 </div> -->
                            <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="http://arxiv.org/abs/2211.16761" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Paper</a> <a href="https://github.com/Yeon07/RISCLIP" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div>
                            <div class="abstract hidden">
                               <p>Recent advances in computer vision and natural language processing have naturally led to active research in multi-modal tasks, including Referring Image Segmentation (RIS). Recent approaches have advanced the frontier of RIS by impressive margins, but they require an additional pretraining stage on external visual grounding datasets to achieve the state-of-the-art performances. We attempt to break free from this requirement by effectively adapting Contrastive Language-Image Pretraining (CLIP) to RIS. We propose a novel framework that residually adapts frozen CLIP features to RIS with Fusion Adapters and Backbone Adapters. Freezing CLIP preserves the backbone's rich, general image-text alignment knowledge, whilst Fusion Adapters introduce multi-modal communication and Backbone Adapters inject new knowledge useful in solving RIS. Our method reaches a new state of the art on three major RIS benchmarks. We attain such performance without additional pretraining and thereby absolve the necessity of extra training and data preparation.</p>
                              </div>
                           </div>
                        </div>
                     </li>
                     <li>
                        <div class="row">
                           <div class="col-sm-4">
                              <figure>
                                 <picture>
                                    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/kim2023pam-480.webp">
                                     </source> 
                                     <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/kim2023pam-800.webp">
                                     </source> 
                                     <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/kim2023pam-1400.webp">
                                     </source> <img src="/assets/img/publication_preview/kim2023pam.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> 
                                  </picture>
                               </figure>
                            </div>
                            <div id="kim2023patch" class="col-sm-8">
                               <div class="title">PAM: Patch Aware Matching for Vision Transformer based Self-Supervised Learning Frameworks</div>
                               <div class="author"> <b>Seoyeon Kim</b>,  Minguk Kang,  and Jaesik Park </div>
                               <div class="periodical"> <em>Image Processing and Image Understanding (IPIU),</em> Bronze Award, 2023 </div>
                               <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> </div>
                               <div class="abstract hidden">
                                  <p>Self-supervised Learning (SSL) is a field that learns meaningful representations from large unlabeled datasets and finetunes such representations to target downstream tasks. Recently, many SSL methods that employ the Vision Transformer based Teacher-Student framework with different losses have been proven effective‚Äîeven effective enough to outperform their supervised counterparts trained with labeled data. In line with this effective ViT-based Teacher-Student framework, we propose a new loss named ‚ÄúPatch Aware Matching (PAM)‚Äù which performs patch token feature distillation across the local view features output from the student and global view features output from the teacher. We hypothesize that such an approach learns ‚Äúlocal-to-global‚Äù correspondence along with local, structural information on the patch level. When trained and evaluated under the k-NN protocol with a ViT-Small/16 backbone, our approach outperforms state-of-the-art methods on the 100 easiest classes of ImageNet-1K but falls behind on 10% of ImageNet. Also, we come across interesting results that suggest that easier classes of ImageNet-1K are more sample efficient. As a work in progress, we aim to further develop our method and investigate sample efficiency of different ImageNet-1K classes.</p>
                              </div>
                           </div>
                        </div>
                     </li>
                  </ol>
               </div>
            </article>
         </div>
      </div>
      <footer class="fixed-bottom">
         <div class="container mt-0"> ¬© Copyright 2023 Seoyeon Kim. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. </div>
      </footer>
      <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> 
   </body>
</html>